import os
import sys
from PIL import Image
import pandas as pd
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import seaborn as sb

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# 创建一个 ImageDataGenerator 实例
datagen = ImageDataGenerator(
    horizontal_flip=True,  # 开启水平翻转
    zoom_range=[0.8, 1.2]   # 开启随机缩放
)

def get_onehot(label):
    
    if label == 'apple': _1hot = [1, 0, 0, 0]
    elif label == 'banana': _1hot = [0, 1, 0, 0]
    elif label == 'orange': _1hot = [0, 0, 1, 0]
    else: _1hot = [0, 0, 0, 1]
    # converting from python list to numpy array
    return np.array([np.asarray(_1hot)])

def getPicPath(ori_path,jud):
    file_list = os.listdir(ori_path+jud+"/")
    ori_xml_list=[]
    for file in file_list:
        if(os.path.splitext(file)[1]=='.jpg'):
            #print('pic file found.')
            #print(file)
            ori_xml_list.append(file)
    return ori_xml_list

def process_image(image_path, size=(100,100)):
    with Image.open(image_path) as img:
        img = img.resize(size)
        # 转换为 RGB 格式（如果需要）
        img_rgb = img.convert('RGB')
        # 将图像数据转换为 numpy 数组
        img_array = np.array([np.asarray(img_rgb)])
        return img_array

def get_label_from_filename(filename):
    # 提取文件名前缀作为标签，具体实现可能根据你的文件名格式而有所不同
    label = os.path.basename(filename).split('_')[0]
    return label

def getPicData(ori_path,jud):
    file_path = getPicPath(ori_path,jud)
    for file in file_path:
        try: 
            x_data = np.concatenate((x_data,process_image(ori_path+jud+"/"+file)),)
        except: 
            x_data = process_image(ori_path+jud+"/"+file)
        try: 
            y_data = np.concatenate((y_data,get_onehot(get_label_from_filename(file))))
        except: 
            y_data = get_onehot(get_label_from_filename(file))
    return x_data,y_data

def create_model():

    model = tf.keras.models.Sequential([
        # 卷积层
        tf.keras.layers.Conv2D(32, (2, 2), activation='relu', input_shape=(100, 100, 3)),
        tf.keras.layers.MaxPooling2D(2, 2),
        
        # 更多的卷积层
        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
        tf.keras.layers.MaxPooling2D(2, 2),

        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
        tf.keras.layers.MaxPooling2D(2, 2),

        # 防止过拟合
        tf.keras.layers.Dropout(0.2),

        # 全连接层
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(128, activation='relu'),
        tf.keras.layers.Dropout(0.1),
        tf.keras.layers.Dense(64, activation='relu'),

        # 输出层
        tf.keras.layers.Dense(4, activation='softmax')
    ])    
    
    # build the model
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    print(model.summary())
    
    return model

def main():
    model = create_model()
    
    tst = os.path.basename(__file__)
    print(__file__[:-len(tst)])
    path = __file__[:-len(tst)]
    
    (x_train,y_train) = getPicData(path,'train')
    (x_test,y_test) = getPicData(path,'test')
    
    print(x_train.shape,x_train.size)
    print(y_train.shape,y_train.size)
    
    #x_train = np.reshape(x_train, (x_train.shape[0], 100, 100, 1))
    #x_test = np.reshape(x_test, (x_test.shape[0], 100, 100, 1))
    
    #y_train - tf.keras.utils.to_categorical(y_train, 3)
    #y_test - tf.keras.utils.to_categorical(y_test, 3)
    
    #print(x_train,y_train)
    #print(x_test,y_test)
    train_generator = datagen.flow(x_train/255, y_train, batch_size=10)

    model.fit(train_generator, epochs=9)

    # showing how we can save our trained model
    model.save(path+'model')
    
    # showing how we can load our trained model
    model = tf.keras.models.load_model(path+'model')

    # test how well our model performs against data
    # that it has not seen before
    model.evaluate(x=x_test/255, y=y_test)

    # 假设你有一个包含图像路径的列表
   

if __name__ == "__main__":
  main()
  
'''
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 conv2d (Conv2D)             (None, 99, 99, 32)        416

 max_pooling2d (MaxPooling2D  (None, 49, 49, 32)       0
 )

 conv2d_1 (Conv2D)           (None, 47, 47, 64)        18496

 max_pooling2d_1 (MaxPooling  (None, 23, 23, 64)       0
 2D)

 conv2d_2 (Conv2D)           (None, 21, 21, 128)       73856

 max_pooling2d_2 (MaxPooling  (None, 10, 10, 128)      0
 2D)

 dropout (Dropout)           (None, 10, 10, 128)       0

 flatten (Flatten)           (None, 12800)             0

 dense (Dense)               (None, 128)               1638528

 dropout_1 (Dropout)         (None, 128)               0

 dense_1 (Dense)             (None, 64)                8256

 dense_2 (Dense)             (None, 4)                 260

=================================================================
Total params: 1,739,812
Trainable params: 1,739,812
Non-trainable params: 0
_________________________________________________________________
None



Epoch 1/9
24/24 [==============================] - 2s 69ms/step - loss: 1.1670 - accuracy: 0.5208
Epoch 2/9
24/24 [==============================] - 2s 70ms/step - loss: 0.7136 - accuracy: 0.7667
Epoch 3/9
24/24 [==============================] - 2s 69ms/step - loss: 0.4980 - accuracy: 0.8458
Epoch 4/9
24/24 [==============================] - 2s 69ms/step - loss: 0.4398 - accuracy: 0.8542
Epoch 5/9
24/24 [==============================] - 2s 69ms/step - loss: 0.2501 - accuracy: 0.9250
Epoch 6/9
24/24 [==============================] - 2s 69ms/step - loss: 0.1603 - accuracy: 0.9375
Epoch 7/9
24/24 [==============================] - 2s 70ms/step - loss: 0.0867 - accuracy: 0.9708
Epoch 8/9
24/24 [==============================] - 2s 69ms/step - loss: 0.4432 - accuracy: 0.8792
Epoch 9/9
24/24 [==============================] - 2s 68ms/step - loss: 0.1802 - accuracy: 0.9500
2023-11-23 10:55:10.503768: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
2/2 [==============================] - 0s 36ms/step - loss: 0.4483 - accuracy: 0.9167
'''